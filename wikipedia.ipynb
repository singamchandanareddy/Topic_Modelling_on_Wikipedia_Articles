{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting text data and storing them in a list (of articles)\n",
    "import io\n",
    "docs = io.open(r\"C:\\Users\\CHANDANA REDDY\\Desktop\\input-1.txt\", mode=\"r\", encoding=\"utf-8\", errors=\"ignore\").read().split('\\n')  # list of strings\n",
    "titles = [docs[i] for i in range(len(docs)) if i % 2 == 0] # list of string titles\n",
    "contents = [docs[i] for i in range(len(docs)) if i % 2 == 1] # list of string contents\n",
    "#print(contents[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['concept', 'angle', 'line', 'plane', 'pair', 'two', 'line', 'two', 'plan', 'line', 'plane', 'space', 'generalise', 'arbitrary', 'dimension', 'generalisation', 'first', 'discuss', 'jordan', 'pair', 'flats', 'euclidean', 'space', 'arbitrary', 'dimension', 'one', 'define', 'set', 'mutual', 'angle', 'invariant', 'isometric', 'transformation', 'euclidean', 'space', 'flats', 'intersect', 'shortest', 'distance', 'one', 'invariant', 'angle', 'call', 'canonical', 'principal', 'concept', 'angle', 'generalise', 'pair', 'flats', 'finite-dimensional', 'inner', 'product', 'space', 'complex', 'numbers.andbeing', 'relate', 'canonical', 'coordinate', 'basic', 'vectors', 'may', 'call', 'canonical.the', 'principal', 'angle', 'vectors', 'define', 'recursively', 'viaif', 'largest', 'angle', 'zero', 'one', 'subspace', 'subset', 'other.if', 'smallest', 'angle', 'zero', 'subspaces', 'intersect', 'least', 'line.the', 'number', 'angle', 'equal', 'zero', 'dimension', 'space', 'two', 'subspaces', 'intersect']\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing/ cleaning the data\n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# remove text between parenthesis\n",
    "# contents = list(map(lambda x: re.sub(r\"\\(.*\\)\",\"\",x), contents))\n",
    "\n",
    "# remove all digits from text\n",
    "contents = list(map(lambda x: re.sub(r\"\\d+\",\"\",x), contents))\n",
    "\n",
    "stop = set(stopwords.words('english')) # set of stopwords\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    # remove stopwords and words that are too short\n",
    "    return [lemma.lemmatize(i, 'v') for i in word_tokenize(doc) if i not in stop and len(i) > 2]\n",
    "cleaned = [clean(page.lower()) for page in contents]\n",
    "\n",
    "print(cleaned[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(25733 unique tokens: ['abelian', 'addition', 'also', 'argument', 'article']...)\n",
      "Dictionary(6621 unique tokens: ['abelian', 'addition', 'also', 'argument', 'article']...)\n",
      "Dictionary(6583 unique tokens: ['abelian', 'addition', 'argument', 'article', 'attribution/share-alike']...)\n",
      "Dictionary(6533 unique tokens: ['abelian', 'addition', 'argument', 'article', 'attribution/share-alike']...)\n"
     ]
    }
   ],
   "source": [
    "# Building word dicitonary\n",
    "from gensim import corpora\n",
    "# create the term dictionary of our corpus; terms are unique; each term is assigned an index\n",
    "dictionary = corpora.Dictionary(cleaned)\n",
    "print(dictionary)\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.7)\n",
    "print(dictionary)\n",
    "stoplist = set('also use make people know many call include part find become like mean often different usually take wikt come give well get since type list say change see refer actually iii aisne kinds pas ask would way something need things want every str'.split())\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
    "dictionary.filter_tokens(stop_ids)\n",
    "print(dictionary)\n",
    "dictionary.filter_n_most_frequent(50)\n",
    "print(dictionary)\n",
    "\n",
    "# This saves the dictionary to the local disk\n",
    "dictionary.save_as_text('./dictionary.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694\n",
      "[(1, 1), (7, 1), (11, 1), (14, 1), (22, 2), (24, 2), (30, 3), (34, 29), (39, 1), (40, 2), (43, 1), (46, 1), (61, 2), (64, 1), (65, 1), (74, 2), (79, 1), (84, 2), (86, 2), (100, 1), (104, 1), (111, 1), (117, 2), (123, 3), (125, 1), (126, 1), (129, 1), (132, 3), (134, 7), (137, 1), (138, 1), (141, 3), (154, 4), (164, 1), (165, 1), (172, 3), (175, 1), (176, 2), (183, 1), (198, 1), (214, 3), (217, 1), (222, 1), (228, 1), (233, 1), (253, 1), (255, 2), (262, 2), (270, 1), (273, 2), (275, 2), (281, 1), (288, 2), (292, 3), (303, 1), (321, 1), (324, 1), (329, 1), (339, 2), (342, 1), (356, 6), (357, 1), (376, 1), (381, 1), (385, 1), (391, 1), (392, 1), (395, 2), (399, 1), (404, 6), (409, 1), (419, 4), (423, 4), (438, 2), (459, 1), (461, 1), (464, 2), (467, 1), (490, 1), (491, 2), (500, 4), (511, 24), (518, 3), (519, 1), (525, 2), (526, 1), (529, 1), (533, 1), (535, 1), (539, 2), (548, 3), (554, 3), (561, 1), (564, 1), (578, 1), (595, 1), (617, 1), (627, 1), (631, 1), (654, 1), (665, 1), (668, 1), (692, 3), (696, 5), (723, 2), (735, 1), (736, 1), (757, 2), (758, 2), (764, 3), (776, 5), (788, 1), (790, 2), (827, 1), (838, 1), (851, 1), (859, 1), (866, 1), (874, 1), (893, 1), (910, 1), (921, 1), (954, 1), (976, 1), (981, 2), (982, 1), (995, 1), (1012, 1), (1027, 2), (1066, 2), (1068, 1), (1074, 3), (1079, 1), (1110, 1), (1117, 1), (1160, 1), (1163, 1), (1178, 1), (1208, 1), (1230, 1), (1232, 1), (1270, 1), (1314, 1), (1330, 1), (1340, 1), (1383, 5), (1495, 3), (1529, 1), (1574, 1), (1639, 1), (1689, 1), (1828, 1), (1856, 1), (2126, 1), (2142, 2), (2151, 2), (2157, 2), (2197, 1), (2227, 2), (2249, 1), (2257, 5), (2271, 1), (2309, 1), (2338, 3), (2403, 2), (2422, 1), (2473, 1), (2516, 1), (2532, 1), (2549, 1), (2579, 1), (2586, 2), (2602, 1), (2665, 1), (2722, 1), (2725, 1), (2760, 1), (2809, 1), (2887, 1), (3108, 6), (3214, 2), (3293, 2), (3345, 1), (3365, 1), (3635, 2), (3848, 1), (3849, 1), (3915, 1), (3998, 23), (4168, 2), (4282, 1), (4287, 2), (4366, 3), (4475, 1), (4520, 1), (4689, 1), (4701, 1), (4744, 1), (4928, 1), (4936, 1), (4950, 3), (4960, 2), (5037, 1), (5104, 4), (5143, 1), (5160, 2), (5175, 1), (5180, 1), (5195, 1), (5225, 1), (5832, 2), (5901, 1), (6105, 1), (6107, 1), (6117, 1), (6164, 12), (6362, 1), (6495, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Creating document-term matrix from vocabulary (dictionary)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in cleaned]\n",
    "print(len(doc_term_matrix))\n",
    "print(doc_term_matrix[693])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   0.010*\"line\" + 0.008*\"coordinate\" + 0.008*\"solution\" + 0.007*\"equations\" + 0.006*\"row\" + 0.005*\"equation\" + 0.005*\"plane\" + 0.004*\"methods\" + 0.004*\"cordic\" + 0.003*\"work\" \n",
      "\n",
      "2   0.006*\"transformation\" + 0.006*\"equations\" + 0.006*\"matrices\" + 0.005*\"solution\" + 0.005*\"line\" + 0.004*\"row\" + 0.004*\"plane\" + 0.004*\"algorithm\" + 0.004*\"product\" + 0.003*\"coordinate\" \n",
      "\n",
      "3   0.007*\"methods\" + 0.007*\"ring\" + 0.006*\"product\" + 0.006*\"element\" + 0.005*\"sequence\" + 0.005*\"zero\" + 0.005*\"vectors\" + 0.004*\"map\" + 0.004*\"sum\" + 0.003*\"equations\" \n",
      "\n",
      "4   0.016*\"group\" + 0.009*\"coordinate\" + 0.006*\"product\" + 0.005*\"rotation\" + 0.005*\"image\" + 0.005*\"sum\" + 0.004*\"line\" + 0.004*\"three\" + 0.004*\"euclidean\" + 0.004*\"matrices\" \n",
      "\n",
      "5   0.010*\"product\" + 0.010*\"row\" + 0.008*\"polynomial\" + 0.007*\"model\" + 0.006*\"equations\" + 0.006*\"matrices\" + 0.005*\"zero\" + 0.005*\"vectors\" + 0.004*\"equation\" + 0.004*\"algorithm\" \n",
      "\n",
      "6   0.009*\"matrices\" + 0.009*\"product\" + 0.006*\"vectors\" + 0.006*\"equations\" + 0.005*\"inverse\" + 0.005*\"line\" + 0.004*\"orthogonal\" + 0.004*\"identity\" + 0.004*\"multiplication\" + 0.003*\"algorithm\" \n",
      "\n",
      "7   0.010*\"map\" + 0.009*\"determinant\" + 0.007*\"vectors\" + 0.006*\"product\" + 0.005*\"matrices\" + 0.005*\"polynomial\" + 0.005*\"multiplication\" + 0.004*\"solution\" + 0.004*\"scalar\" + 0.004*\"plane\" \n",
      "\n",
      "8   0.007*\"rank\" + 0.006*\"vectors\" + 0.006*\"equations\" + 0.005*\"matrices\" + 0.005*\"product\" + 0.005*\"coordinate\" + 0.005*\"solution\" + 0.004*\"map\" + 0.004*\"three\" + 0.003*\"row\" \n",
      "\n",
      "9   0.006*\"coordinate\" + 0.005*\"product\" + 0.005*\"finite\" + 0.004*\"geometry\" + 0.004*\"equations\" + 0.004*\"vectors\" + 0.004*\"equation\" + 0.003*\"map\" + 0.003*\"row\" + 0.003*\"polynomial\" \n",
      "\n",
      "10   0.014*\"ring\" + 0.009*\"matrices\" + 0.008*\"group\" + 0.007*\"product\" + 0.006*\"polynomial\" + 0.006*\"map\" + 0.006*\"coordinate\" + 0.004*\"vectors\" + 0.004*\"multiplication\" + 0.004*\"finite\" \n",
      "\n",
      "11   0.010*\"sequence\" + 0.010*\"group\" + 0.009*\"equations\" + 0.008*\"vectors\" + 0.007*\"coordinate\" + 0.006*\"solution\" + 0.006*\"product\" + 0.006*\"equation\" + 0.004*\"line\" + 0.004*\"finite\" \n",
      "\n",
      "12   0.007*\"quantum\" + 0.005*\"group\" + 0.005*\"coordinate\" + 0.005*\"map\" + 0.005*\"operator\" + 0.004*\"state\" + 0.004*\"matrices\" + 0.004*\"model\" + 0.003*\"mechanics\" + 0.003*\"operators\" \n",
      "\n",
      "13   0.013*\"vectors\" + 0.007*\"product\" + 0.007*\"equations\" + 0.006*\"span\" + 0.006*\"row\" + 0.006*\"polynomial\" + 0.006*\"matrices\" + 0.005*\"rank\" + 0.005*\"equation\" + 0.004*\"solution\" \n",
      "\n",
      "14   0.005*\"vectors\" + 0.005*\"row\" + 0.005*\"quantum\" + 0.004*\"engineer\" + 0.004*\"rotation\" + 0.004*\"product\" + 0.004*\"group\" + 0.004*\"coordinate\" + 0.004*\"column\" + 0.003*\"hilbert\" \n",
      "\n",
      "15   0.006*\"polynomial\" + 0.005*\"coordinate\" + 0.005*\"product\" + 0.004*\"model\" + 0.004*\"data\" + 0.004*\"leibniz\" + 0.004*\"methods\" + 0.004*\"cordic\" + 0.004*\"equations\" + 0.003*\"numerical\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training LDA model\n",
    "from gensim.models.ldamodel import LdaModel as Lda\n",
    "\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=15, id2word = dictionary)\n",
    "\n",
    "# Showing the 15 identified topics after the model is trained, where top 10 key terms are listed for each topic\n",
    "for topic in ldamodel.print_topics(num_topics=15, num_words=10):\n",
    "    print(topic[0]+1, \" \", topic[1],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles(ID) in Cluster 1: 26, 64, 78, 126, 139, 144, 165, 167, 179, 195, 203, 205, 219, 227, 265, 268, 291, 305, 306, 325, 336, 345, 378, 409, 420, 427, 434, 439, 448, 454, 503, 504, 535, 541, 561, 564, 567, 639, 644, 673, 676, 686\n",
      "\n",
      "Articles(ID) in Cluster 2: 28, 52, 85, 109, 214, 277, 283, 331, 344, 350, 384, 412, 431, 442, 444, 479, 489, 516, 518, 601, 652, 677, 682, 684, 692\n",
      "\n",
      "Articles(ID) in Cluster 3: 25, 36, 39, 80, 100, 116, 118, 122, 123, 129, 166, 184, 196, 199, 209, 226, 229, 234, 246, 278, 287, 300, 318, 333, 353, 362, 373, 398, 411, 435, 437, 443, 456, 459, 460, 482, 486, 500, 522, 532, 537, 556, 589, 597, 598, 604, 622, 624, 632, 635, 640, 664, 668\n",
      "\n",
      "Articles(ID) in Cluster 4: 2, 17, 21, 30, 32, 53, 55, 68, 91, 95, 110, 138, 145, 194, 211, 220, 239, 241, 249, 261, 319, 328, 330, 332, 355, 368, 369, 380, 382, 391, 393, 405, 406, 417, 418, 462, 466, 468, 469, 485, 507, 514, 521, 530, 542, 552, 566, 617, 649, 660, 665, 672\n",
      "\n",
      "Articles(ID) in Cluster 5: 8, 12, 16, 18, 24, 48, 51, 58, 71, 76, 84, 96, 113, 120, 128, 143, 146, 147, 153, 159, 161, 162, 171, 177, 182, 183, 197, 216, 221, 224, 235, 243, 274, 281, 285, 290, 320, 322, 343, 352, 360, 374, 377, 400, 402, 410, 416, 425, 429, 430, 438, 441, 453, 458, 464, 470, 484, 491, 502, 506, 523, 526, 529, 543, 558, 565, 569, 578, 583, 594, 602, 610, 620, 621, 625, 631, 661, 662, 674, 693\n",
      "\n",
      "Articles(ID) in Cluster 6: 5, 29, 33, 37, 43, 45, 47, 90, 115, 168, 169, 174, 176, 178, 186, 201, 213, 218, 223, 310, 316, 349, 397, 407, 419, 452, 483, 488, 517, 550, 579, 581, 593, 603, 650, 679\n",
      "\n",
      "Articles(ID) in Cluster 7: 13, 54, 57, 70, 81, 102, 112, 114, 121, 127, 134, 151, 163, 202, 250, 273, 307, 315, 338, 341, 371, 372, 389, 403, 422, 449, 492, 505, 510, 511, 524, 559, 584, 585, 591, 600, 626, 636, 638, 671\n",
      "\n",
      "Articles(ID) in Cluster 8: 31, 41, 73, 86, 108, 117, 141, 208, 247, 295, 302, 304, 314, 321, 396, 465, 571, 577, 605, 646, 680, 685\n",
      "\n",
      "Articles(ID) in Cluster 9: 3, 6, 7, 11, 46, 49, 61, 69, 72, 77, 83, 87, 104, 107, 137, 148, 154, 256, 293, 299, 317, 346, 404, 525, 548, 553, 570, 572, 596, 615, 619, 647, 656, 675, 687, 688, 689, 690, 691\n",
      "\n",
      "Articles(ID) in Cluster 10: 0, 1, 4, 9, 22, 27, 34, 40, 59, 93, 99, 101, 124, 132, 149, 160, 185, 187, 200, 206, 232, 236, 237, 240, 255, 257, 263, 264, 270, 275, 289, 292, 301, 327, 340, 342, 367, 376, 379, 383, 385, 388, 390, 408, 413, 414, 415, 436, 446, 447, 478, 487, 496, 509, 528, 544, 557, 573, 582, 587, 595, 599, 618, 627, 633, 637, 642, 653, 658, 659, 667, 678\n",
      "\n",
      "Articles(ID) in Cluster 11: 10, 14, 23, 62, 63, 65, 79, 97, 105, 125, 136, 140, 150, 173, 192, 198, 217, 244, 252, 260, 267, 269, 311, 323, 354, 356, 366, 375, 381, 426, 428, 445, 455, 494, 498, 508, 513, 555, 575, 586, 669\n",
      "\n",
      "Articles(ID) in Cluster 12: 19, 38, 60, 133, 142, 157, 170, 172, 180, 191, 215, 230, 254, 271, 272, 280, 284, 288, 326, 329, 359, 392, 421, 476, 477, 490, 493, 499, 520, 547, 568, 574, 576, 580, 592, 606, 608, 611, 623, 628, 657, 670, 683\n",
      "\n",
      "Articles(ID) in Cluster 13: 20, 42, 44, 66, 67, 82, 94, 98, 106, 119, 152, 158, 189, 190, 207, 228, 238, 245, 248, 259, 262, 266, 279, 294, 298, 309, 312, 313, 335, 337, 386, 387, 424, 450, 463, 471, 472, 475, 480, 481, 495, 501, 533, 534, 538, 540, 545, 546, 551, 560, 562, 588, 590, 609, 613, 616, 629, 630, 643, 645, 648, 651, 666, 681\n",
      "\n",
      "Articles(ID) in Cluster 14: 92, 135, 188, 204, 233, 253, 286, 361, 365, 395, 423, 461, 539, 549, 612, 634, 654\n",
      "\n",
      "Articles(ID) in Cluster 15: 15, 35, 50, 56, 74, 75, 88, 89, 103, 111, 130, 131, 155, 156, 164, 175, 181, 193, 210, 212, 222, 225, 231, 251, 276, 282, 296, 297, 308, 324, 334, 339, 347, 348, 351, 357, 358, 363, 364, 370, 394, 399, 432, 433, 440, 457, 473, 474, 497, 515, 519, 527, 531, 536, 554, 563, 607, 614, 641, 655, 663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clustering documents based on topics extracted from LDA model \n",
    "from operator import itemgetter\n",
    "def cluster(doc_term_matrix, num):\n",
    "    doc_topics = ldamodel.get_document_topics(doc_term_matrix, minimum_probability=0.20)\n",
    "    result = [[] for i in range(num)]\n",
    "    for k,topic in enumerate(doc_topics):\n",
    "        # Some articles do not have a topic\n",
    "        if topic:\n",
    "            topic.sort(key = itemgetter(1), reverse=True)\n",
    "            result[topic[0][0]].append(k)\n",
    "    for k in range(len(result)):\n",
    "        print('Articles(ID) in Cluster ' + str(k+1) + ': ' + ', '.join(map(str, result[k])))\n",
    "        print()\n",
    "    return result\n",
    "cluster_result = cluster(doc_term_matrix, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles in Cluster 1: /wiki/Linear algebra, Interval propagation, Trajectory (fluid mechanics), Hundred-dollar, Hundred-digit Challenge problems, Iterative method, Loss of significance, Local convergence, Signal-flow graph, The Nine Chapters on the Mathematical Art, Fangcheng (mathematics), System of linear equations, Balanced set, Plane (geometry), List of finite element software packages, Big M method, S-procedure, System of linear equations, Significant figures, Template:Linear algebra, System of linear equations, Residual (numerical analysis), Linear inequality, Intersection (Euclidean geometry), Van Wijngaarden transformation, Sedrakyan's inequality, System of linear equations, Portal:Linear algebra, Rotation of axes, Zassenhaus algorithm, Three-dimensional space, Telegraphy, Flat (geometry), Line–line intersection, Approximation error, System of linear equations, Line (geometry), Scarborough criterion, Translation of axes, Series acceleration, Superconvergence, Portal:Linear algebra, Coordinate system\n",
      "\n",
      "Articles in Cluster 2: Hamming space, Sylvester's law of inertia, Fundamental matrix (computer vision), Indeterminate system, Pohlke's theorem, Vector projection, Truncation, Guard digit, Stabilizer code, Symplectic vector space, Piecewise linear continuation, Lapped transform, Numerical continuation, Transformation matrix, Bidiagonal matrix, Corank, Tapering (mathematics), Unitary transformation, Round-off error, Generalizations of Pauli matrices, Spread of a matrix, Schur complement, Generalized Gauss–Newton method, Codimension, Ambient space\n",
      "\n",
      "Articles in Cluster 3: Hilbert space, Stiffness matrix, Endomorphism, Bilinear form, Pseudo-spectral method, Orthogonal Procrustes problem, Runge–Kutta methods, Sesquilinear form, Adaptive stepsize, Bilinear form, Dimension theorem for vector spaces, Weakened weak form, Material point method, Kernel (algebra), Peano kernel theorem, Pseudospectral knotting method, Generalized-strain mesh-free formulation, Cardinality, Legendre pseudospectral method, Lanczos approximation, Multigrid method, Lattice reduction, Meshfree methods, Numerical methods in fluid mechanics, Orthogonal complement, Quotient space (linear algebra), Hermes Project, Ross–Fahroo pseudospectral method, Dual space, Zero object (algebra), Multilinear form, Zero mode, Set (mathematics), Cauchy–Schwarz inequality, Dimension (vector space), Element (mathematics), Uzawa iteration, Shanks transformation, Dimension (vector space), Dual space, Flat pseudospectral method, Newton–Krylov method, Bellman pseudospectral method, Spectral method, Hilbert space, Numerical linear algebra, Multilevel Monte Carlo method, Mesh generation, GetFEM++, Cauchy–Schwarz inequality, Padé table, Rate of convergence, Predictor–corrector method\n",
      "\n",
      "Articles in Cluster 4: Angles between flats, Definite quadratic form, Modulus of smoothness, Atmosphere, Quadratic form, Geodesy, Quadratic form, CSS code, Rotation (mathematics), Semi-simple operator, Image (mathematics), Homography, Abelian group, Schur product theorem, Homogeneous coordinates, Peetre's inequality, Euclidean group, Lorentz transformation, History of Lorentz transformations, Pseudovector, Möbius transformation, Trilinear coordinates, Euclidean space, Image (mathematics), Figure of the Earth, Liouville space, Rota's basis conjecture, Coordinate system, Hyperplane, Special linear group, Perspectivity, Loewner order, Definite quadratic form, Asymmetric norm, Three-dimensional rotation operator, List of linear algebra topics, Majorization, Squeeze mapping, Direct sum of modules, Absolutely convex set, Isometry, Reflection (mathematics), Bijection, Coates graph, Self-adjoint, Image (mathematics), Complex plane, List of operator splitting topics, Cartesian coordinate system, Eigenplane, Quaternionic matrix, Dependence relation\n",
      "\n",
      "Articles in Cluster 5: Curse of dimensionality, Bernstein polynomial, Sinc numerical methods, Polarization identity, Boundary particle method, Overlap–add method, Conjugate transpose, Mixed linear complementarity problem, List of vector spaces in mathematics, Ross–Fahroo lemma, Linear regression, Matrix calculus, Mathematical model, Vector field reconstruction, Finite field, Matrix congruence, Amitsur–Levitzki theorem, Newton's identities, Zero of a function, Monic polynomial, Row echelon form, Elementary matrix, Monte Carlo method, Backus–Gilbert method, Linear programming, Permanent (mathematics), Zero matrix, Entanglement-assisted stabilizer formalism, Nonlinear eigenproblem, Finite difference, Polynomial, Ross' π lemma, Numerical stability, Quadratic eigenvalue problem, Gaussian elimination, Triple product, Radial basis function, Complex conjugate, Unisolvent functions, Faddeev–LeVerrier algorithm, Tikhonov regularization, Transpose, Restricted isometry property, Non-negative matrix factorization, Row equivalence, Identifiability analysis, Nonstandard finite difference scheme, Polynomial, Lie group integrator, Low-discrepancy sequence, Newton fractal, Order of accuracy, Elementary matrix, Numerical range, Jenkins–Traub algorithm, Seven-dimensional cross product, Pseudoscalar, Partial differential equation, Linear function, Computing the permanent, Reduction (mathematics), Model order reduction, Discretization, Matrix difference equation, Elementary matrix, Transpose of a linear map, Closed-form expression, Well-posed problem, Gaussian elimination, Vector-valued function, Multiphysics, Cross product, Unrestricted algorithm, Wilkinson's polynomial, Curve fitting, Mathematical analysis, Square-free polynomial, Manifold, Regularized least squares, Butcher group\n",
      "\n",
      "Articles in Cluster 6: Bendixson's inequality, Fredholm's theorem, Orthonormality, Skew-Hermitian matrix, Matrix multiplication, Cache (computing), Invertible matrix, Kempner series, Propagation of uncertainty, Spherical basis, Identity matrix, Orthogonal transformation, Invertible matrix, Invertible matrix, Matrix addition, FEE method, Orthogonality, Lady Windermere's Fan (mathematics), Invertible matrix, Orthonormal basis, LAPACK, Normal matrix, Padé approximant, Schmidt decomposition, Invertible matrix, Birkhoff orthogonality, Vectorization (mathematics), Quadruple product, Finite von Neumann algebra, Multiplicative inverse, Orthogonal basis, Productive matrix, Isotonic regression, Rod calculus, Sylvester's determinant identity, Woodbury matrix identity\n",
      "\n",
      "Articles in Cluster 7: Difference quotient, James Joseph Sylvester, Scalar multiplication, Linear map, Benjamin Peirce, Hermite normal form, Rayleigh quotient, Digital Library of Mathematical Functions, Resolvent set, Cramer's rule, Cramer's rule, Matrix determinant lemma, Scalar multiplication, Karlsruhe Accurate Arithmetic, Cokernel, Determinant, Digital Library of Mathematical Functions, Linear map, Adjugate matrix, Isomorphism, Sherman–Morrison formula, Gabriel Cramer, Rayleigh's quotient in vibrations analysis, Rule of Sarrus, Linear map, Determinant, Arthur Cayley, Trace diagram, Eigengap, Graded (mathematics), Canonical map, Karlsruhe Accurate Arithmetic, Zech's logarithm, Coopmans approximation, Orthogonal diagonalization, Homogeneous function, Isomorphism, Map (mathematics), Cramer's rule, Giuseppe Peano\n",
      "\n",
      "Articles in Cluster 8: Level set (data structures), Nonnegative rank (linear algebra), Multi-core processor, Relative dimension, Galerkin method, Linearity, Basic Linear Algebra Subprograms, Intersection curve, Triangle inequality, Euclidean vector, Augmented matrix, Abramowitz and Stegun, Estrin's scheme, Abramowitz and Stegun, 3D projection, Euclidean vector, Orthographic projection, Affine arithmetic, Coefficient matrix, Abramowitz and Stegun, Compressed sensing, Discrete wavelet transform\n",
      "\n",
      "Articles in Cluster 9: Gradient discretisation method, Closest point method, Truncation error, List of uncertainty propagation software, Linear form, Weyr canonical form, Frame (linear algebra), Bi-directional delay line, Frobenius normal form, Regularized meshless method, Linear form, Blossom (functional), Overcompleteness, File:Portal-puzzle.svg, Finite volume method, Finite Legendre transform, Differential geometry, Whitney inequality, Sparse grid, Geometry, Linear approximation, Shear matrix, Singular boundary method, Frobenius normal form, Transfer matrix, Convex cone, James H. Wilkinson, Synthetic geometry, Bunch–Nielsen–Sorensen formula, James H. Wilkinson, Method of fundamental solutions, Discrete Fourier transform, Partial differential algebraic equation, Quantification of margins and uncertainties, Continuous wavelet, Von Neumann stability analysis, Explicit algebraic stress model, Shear mapping, Discretization error\n",
      "\n",
      "Articles in Cluster 10: Free module, Binary operation, Multilinear algebra, General linear group, Tensor product, Linear algebra, List of linear algebra topics, Dieudonné determinant, Quaternion, Rank factorization, Affine space, Fusion frame, Matrix similarity, Hermann Grassmann, Field extension, Line segment, Movable cellular automaton, Successive parabolic interpolation, Trace identity, Cartesian tensor, Quaternionic vector space, Characteristic polynomial, Linear equation over a ring, Change of basis, Sigma approximation, Riemann solver, Diagonal matrix, Module homomorphism, Dual number, Hypercomplex number, Eigenvalues and eigenvectors, Function (mathematics), 2 × 2 real matrices, Pairing, Wild problem, Characteristic polynomial, Polynomial ring, Segre classification, Semi-simplicity, Steinitz exchange lemma, Commutative ring, Matrix analysis, Linear equation over a ring, Field (mathematics), Projective space, Aitken's delta-squared process, Skew-Hamiltonian matrix, Scalar (mathematics), Semilinear map, Matrix (mathematics), Finitely generated module, Dual basis in a field extension, Timeline of numerical analysis after 1945, General linear group, Centrosymmetric matrix, Complex conjugate vector space, Principal ideal domain, Hilbert–Poincaré series, Polynomial basis, Algebra over a field, Category of modules, Coordinate space, Processor (computing), Quasinorm, Hurwitz determinant, Vector space, Abstract algebra, Golden–Thompson inequality, Diagonalizable matrix, Invariants of tensors, Ring (mathematics), Affine space\n",
      "\n",
      "Articles in Cluster 11: Unit vector, Linear equation, Differential-algebraic system of equations, Flag (linear algebra), Immanant, Range (mathematics), Function space, Stokes operator, De Casteljau's algorithm, Split-complex number, De Boor's algorithm, Standard basis, Overlap–save method, Boundary knot method, Group representation, Real number, Commutation matrix, Null vector, Sequence, Independent equation, Function composition, Function space, Overdetermined system, Relative change and difference, Geometric transformation, Minimum polynomial extrapolation, Levinson recursion, Levi-Civita symbol, Flag (linear algebra), Underdetermined system, Delta operator, Analytic geometry, Coordinate vector, Function composition, Richardson extrapolation, Sequence, Generator (mathematics), Leibniz formula for determinants, Scale co-occurrence matrix, Coordinate vector, Pointwise\n",
      "\n",
      "Articles in Cluster 12: Translation, Fredholm alternative, ND4S, A Treatise on Electricity and Magnetism, Wave function, Probability box, Maple (software), Antiunitary operator, ND4J (software), Purification of quantum state, Dynamic relaxation, Charles Sanders Peirce, Multilevel fast multipole method, Choi's theorem on completely positive maps, MATLAB, Spectral theorem, Graphics processing unit, Wolfram Language, Finitely generated abelian group, Normal basis, Quantum mechanics, Spinors in three dimensions, Equipollence (geometry), Controlled invariant subspace, Field (physics), Defective matrix, Partial trace, Mathematics, Projection (mathematics), Error analysis (mathematics), Weather forecasting, Axiom, Modeshape, Eigenoperator, Spectral theory, Nyström method, Cyclic subspace, Integer points in convex polyhedra, Conformable matrix, Interval arithmetic, Mechanics, Invariant subspace, Tensor operator\n",
      "\n",
      "Articles in Cluster 13: Rank (linear algebra), k-frame, Matrix norm, Sublinear function, Trace (linear algebra), Singular value decomposition, Linear span, Proper generalized decomposition, Book:Linear algebra, Hermitian adjoint, Projection (linear algebra), Canonical basis, Row and column spaces, Norm (mathematics), Antilinear map, Linear span, Dual basis, Condition number, Dual norm, Generalized singular value decomposition, Bra–ket notation, Dot product, Linear span, Basis (linear algebra), Generalized eigenvector, Kernel (linear algebra), Jordan normal form, Linear independence, Rank (linear algebra), Gram–Schmidt process, Nonlinear system, Jordan–Chevalley decomposition, Functional analysis, Lp space, Haynsworth inertia additivity formula, Symmetric matrix, Nonlinear system, Linear independence, Bra–ket notation, Gershgorin circle theorem, Weyl's inequality, Kernel (linear algebra), Linear combination, Orthogonalization, Mode of a linear field, Linear subspace, Interval contractor, Orientation of a vector bundle, Gram–Schmidt process, Total set, Fundamental theorem of linear algebra, Kernel (linear algebra), Jordan normal form, Eigenvalue perturbation, Linear complementarity problem, Reality structure, Kernel (linear algebra), Basis (linear algebra), Dual basis, Subset, Linear system, Inner product space, Linear subspace, Linear combination\n",
      "\n",
      "Articles in Cluster 14: Truncated power function, Fast multipole method, Computational complexity, Algorithm, Engineering, Orthonormal function system, Orientation (vector space), Gal's accurate tables, Significance arithmetic, Symbolic-numeric computation, Semi-infinite programming, Projection-valued measure, Row and column vectors, Rotation, Rigid body dynamics, Artificial precision, Row and column vectors\n",
      "\n",
      "Articles in Cluster 15: Kahan summation algorithm, Robotics, Barycentric coordinate system, René Descartes, List of numerical analysis topics, Z-order curve, False precision, CORDIC, Orthant, Remez algorithm, CORDIC, Trigonometric tables, Computer vision, CORDIC, Computational statistics, Numerical analysis, Numerical model of the Solar System, Parareal, Surrogate model, CORDIC, CORDIC, Numerical differentiation, CORDIC, Computational science, Simpson's rule, Chebyshev nodes, CORDIC, Horner's method, CORDIC, CORDIC, CORDIC, Minimax approximation algorithm, CORDIC, Matrix Chernoff bound, Multi-time-step integration, Joint spectral radius, Equioscillation theorem, Adjoint state method, Numerical integration, CORDIC, CORDIC, Numeric precision in Microsoft Excel, Order of approximation, Numerical method, K-SVD, CORDIC, Approximation theory, Chebyshev pseudospectral method, Carl Friedrich Gauss, Applied element method, Gottfried Wilhelm Leibniz, CORDIC, Hypot, Pairwise summation, Savitzky–Golay filter, Basis function, Approximation, Numerical error, Computer graphics, Bernstein's constant, Clenshaw algorithm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing the exact document titles in each cluster\n",
    "for k in range(len(cluster_result)):\n",
    "    print('Articles in Cluster ' + str(k+1) + ': ' + ', '.join(map(lambda x: titles[x], cluster_result[k])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.0007637082), (1, 0.00036834157), (2, 0.000533453), (3, 0.0009955846), (4, 0.000613399), (5, 0.0006990954), (6, 0.0002917314), (7, 0.00051765045), (8, 0.0011452276), (9, 0.00017415907), (10, 0.00023260496), (11, 0.00040177695), (12, 0.0005660611), (13, 0.00025470392), (14, 0.00014823505)]\n"
     ]
    }
   ],
   "source": [
    "term_topics = ldamodel.get_term_topics('convex', minimum_probability=0.000001)\n",
    "print(term_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Top 7 articles related to input -------\n",
      "Computational complexity \n",
      " 0.9984664 \n",
      "\n",
      "Artificial precision \n",
      " 0.9787706 \n",
      "\n",
      "Semi-infinite programming \n",
      " 0.9698835 \n",
      "\n",
      "Engineering \n",
      " 0.9161838 \n",
      "\n",
      "Symbolic-numeric computation \n",
      " 0.91512513 \n",
      "\n",
      "Projection-valued measure \n",
      " 0.8645662 \n",
      "\n",
      "Orthonormal function system \n",
      " 0.8444185 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting related documents based on a term \n",
    "def get_related_documents(term, top, doc_term_matrix):\n",
    "    print('------- Top', top, 'articles related to',term,'-------')\n",
    "    related_docs = []\n",
    "    doc_topics = ldamodel.get_document_topics(doc_term_matrix, minimum_probability=0.20)\n",
    "    term_topics = ldamodel.get_term_topics(term, minimum_probability=0.000001)\n",
    "    term_topics.sort(key = itemgetter(1), reverse=True)\n",
    "    for k,topic in enumerate(doc_topics):\n",
    "        if topic:\n",
    "            topic.sort(key = itemgetter(1), reverse=True)\n",
    "            if topic[0][0] == term_topics[0][0]:\n",
    "                related_docs.append((k,topic[0][1]))\n",
    "    related_docs.sort(key = itemgetter(1), reverse=True)\n",
    "    result = []\n",
    "    for j,doc in enumerate(related_docs):\n",
    "        print(titles[doc[0]],\"\\n\",doc[1],\"\\n\")   \n",
    "        result.append(titles[doc[0]])\n",
    "        if j == top - 1:\n",
    "            break\n",
    "related_docs = get_related_documents('input', 7, doc_term_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ldamodel.pkl','wb') as openfile:\n",
    "    pickle.dump(ldamodel,openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ldamodel.pkl','rb') as f:\n",
    "    ldamodel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Top 7 articles related to convex -------\n",
      "Frame (linear algebra) \n",
      " 0.9966995 \n",
      "\n",
      "Convex cone \n",
      " 0.9965028 \n",
      "\n",
      "Von Neumann stability analysis \n",
      " 0.9950839 \n",
      "\n",
      "Gradient discretisation method \n",
      " 0.99346876 \n",
      "\n",
      "Linear approximation \n",
      " 0.99240863 \n",
      "\n",
      "James H. Wilkinson \n",
      " 0.9911048 \n",
      "\n",
      "James H. Wilkinson \n",
      " 0.9911048 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting related documents based on a term \n",
    "def get_related_documents(term, top, doc_term_matrix):\n",
    "    print('------- Top', top, 'articles related to',term,'-------')\n",
    "    related_docs = []\n",
    "    doc_topics = ldamodel.get_document_topics(doc_term_matrix, minimum_probability=0.20)\n",
    "    term_topics = ldamodel.get_term_topics(term, minimum_probability=0.000001)\n",
    "    term_topics.sort(key = itemgetter(1), reverse=True)\n",
    "    for k,topic in enumerate(doc_topics):\n",
    "        if topic:\n",
    "            topic.sort(key = itemgetter(1), reverse=True)\n",
    "            if topic[0][0] == term_topics[0][0]:\n",
    "                related_docs.append((k,topic[0][1]))\n",
    "    related_docs.sort(key = itemgetter(1), reverse=True)\n",
    "    result = []\n",
    "    for j,doc in enumerate(related_docs):\n",
    "        print(titles[doc[0]],\"\\n\",doc[1],\"\\n\")   \n",
    "        result.append(titles[doc[0]])\n",
    "        if j == top - 1:\n",
    "            break\n",
    "related_docs = get_related_documents('convex', 7, doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "def get_theme(doc, cluster_result):\n",
    "    doc_id = titles.index(doc)\n",
    "    if doc_id == -1:\n",
    "        print('Document not found.')\n",
    "        return\n",
    "    for i, cluster in enumerate(cluster_result):\n",
    "        if doc_id in cluster:\n",
    "            return i+1\n",
    "    return 0\n",
    "cluster_num = get_theme('Absolutely convex set', cluster_result)\n",
    "print(cluster_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=694, num_nnz=169581)\n",
      "(0, 0.045342656413852538)\n"
     ]
    }
   ],
   "source": [
    "# Implementing tf-idf model; the only information needed from the previous part is the doc_term_matrix\n",
    "from gensim.models import TfidfModel, LsiModel\n",
    "tfidf_model = TfidfModel(doc_term_matrix, dictionary = dictionary)\n",
    "print(tfidf_model)\n",
    "vector = tfidf_model[doc_term_matrix[0]]\n",
    "print(vector[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LsiModel(num_terms=6533, num_topics=200, decay=1.0, chunksize=20000)\n"
     ]
    }
   ],
   "source": [
    "# Implementing LSI model; the only information needed from the previous part is the doc_term_matrix\n",
    "lsi_model = LsiModel(doc_term_matrix, id2word=dictionary)\n",
    "print(lsi_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694\n"
     ]
    }
   ],
   "source": [
    "# Creating the similarity matrix from simple bag-of-words model (# of documents * # of documents)\n",
    "from gensim import similarities\n",
    "\n",
    "index = similarities.MatrixSimilarity(doc_term_matrix, num_features=len(dictionary))\n",
    "print(len(index[doc_term_matrix[693]])) # 694 * 694 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training tf-idf model from bag-of-word dataset\n",
    "model_tfidf = TfidfModel(doc_term_matrix, id2word=dictionary, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applying tf-idf model to all vectors\n",
    "from gensim.corpora import MmCorpus\n",
    "MmCorpus.serialize('./corpus_tfidf.mm', model_tfidf[doc_term_matrix], progress_cnt=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixSimilarity<694 docs, 6533 features>\n"
     ]
    }
   ],
   "source": [
    "corpus_tfidf = MmCorpus('./corpus_tfidf.mm') # Loading back the corpus file after applying tf-idf\n",
    "model_lsi = LsiModel(corpus_tfidf, num_topics=15, id2word=dictionary)\n",
    "# Applying LSI model to all vectors\n",
    "index = similarities.MatrixSimilarity(model_lsi[corpus_tfidf], num_features=len(dictionary))\n",
    "print(index)\n",
    "index.save('./lsi_index.mm') # Saving the similarity matrix to a local matrix market file named './lsi_model.mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694\n"
     ]
    }
   ],
   "source": [
    "# Loading the similarity matrix back from the local file\n",
    "similarity_matrix = similarities.MatrixSimilarity.load('./lsi_index.mm')\n",
    "print(len(similarity_matrix))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
